1.Questions 1-2 are about noisy targets.

two situation.

First, prediction is right, but was affected by noise. (1-u)(1-λ)
Second, prediction is wrong, and was not addected by noise. uλ

A:(1-u)(1-λ)+uλ -> D

2. Following Question 1, with what value of λ will the performance of h be independent of μ?

Explaination: μ cannot affect the result of (1-u)(1-λ)+uλ

(1-u)(1-λ)+uλ => u(2λ-1)+(1-λ)  When λ= 0.5, u(2λ-1 will always be 0 

A: λ=0.5 -> D

3. Questions 3-5 are about generalization error, and getting the feel of the bounds numerically. 

ϵ=0.05 (generalizationerror), δ=0.05(confidenceerror), dvc=10


ϵ=sqrt((8/N)ln((4(2N)^dvc))/δ),  put the above value into the equation

sqrt(log((4*(2*N)^10)/0.05,exp(1))*(8/N))
N=420000 ϵ=0.05178593
N=440000 ϵ=0.05067881
N=460000 ϵ=0.04964278 * The closest 
N=480000 ϵ=0.04867048
N=500000 ϵ=0.04775557

A: N=460000 ->C

4. There are a number of bounds on the generalization error ϵ, all holding with probability at least......

Original VC bound:             ϵ<=0.6321749
Rademacher Penalty Bound:      ϵ<=0.3313088
Parrondo and Van den Broek:    ϵ<=0.2236206
Devroye:                       ϵ<=??
Variant VC bound:              ϵ<=0.860426

A: Parrondo and Van den Broek

5. Continuing from Question 4, for small N, say N=5, which bound is the tightest (smallest)? (wrong)
Original VC bound:             ϵ<=13.82816
Rademacher Penalty Bound:      ϵ<=7.048777
Parrondo and Van den Broek:    ϵ<=4.899321
Devroye:                       ϵ<=20.343046593251703
Variant VC bound:              ϵ<=16.26411

A: Parrondo and Van den Broek

6. In Questions 6-11, you are asked to play with the growth function or VC-dimension of some hypothesis sets

First situation  : Select 2 points from N points. Within is positive(+1) and without is negative(-1)
Second Situation : Select 2 points from N points. Within is negative(-1) and without is positive(+1)
2*C(N,2)=N^2-N+2
A: N^2-N+2 ->A

7.Continuing from the previous problem, what is the VC-dimension of the hypothesis set of "positive-and-negative intervals on 
R''? wrong

N=1
N^2-N+2=2 > 2^N
N=2
N^2-N+2=4 = 2^N
N=3
9-3+2=8 = 2^N=8 

N=4
16-4+2=14 = 2^4=16  breakpoint

VC-dimension= last non-breakpoint

Therefore, the answer is 3
A:3 -> A

8.
What is the growth function of "positive donuts?

donut is actually an interval question. When one point is have equal distance to (0,0) with other points, they will have the same sign.

the line is like following

0-o-o-o-o-o-o-o

pick two o from this interval, which is C(N+1,2) (including 0), and add one option that is select the same point.

Thus, C(N+1,2)+1

A: C(N+1,2)+1 -> B

9. Consider the "polynomial discriminant'' hypothesis set of degree What is the VC-dimension of such an H?

This is actually perceptron. As we learn from the course, the answer is D+1

A: D+1 -> B

10. Consider the "simplified decision trees'' hypothesis set on.....

vi = [[xi > ti]] represents that if x>t, v=+1. if x<=t, v=-1
S is the collection of vectors in {0,1}^2, which means S has four vectors, s1=(0,0), s2=(0,1), s3=(1,0), s4=(1,1)

for further explaination can go check here
http://countchu2.blogspot.com/2018/01/machine-learning-foundations-question-10.html

A: A

11.Consider the "triangle waves'' hypothesis set on R, which is given by......

in this question, we know that

0<axmod4<1    +

1<axmod4<3    -

3<axmod4<4    +

for N points, you can always find a point to fit into this interval. No matter how many points are there.

For example, 2 points  x1=7.5 y1=+1, x2=1.5 y2=-1,   (o,x)
                       x1=7.5 y1=+1, x2=7.4 y2=+1,   (o,o)
                       x1=1.6 y1=-1, x2=1.5 y2=-1,   (x,x)
                       x1=1.6 y1=-1, x2=7.4 y2=-1,   (x,o)
you can create any kind of combination to shatter all the possible points.

Therefore, there is no VC-dimension
A: C


12. In Questions 12-15, you are asked to verify some properties or bounds on the growth function and VC-dimension.

The bounding function will be B(N,k)<= sigma C(N,i), i=0~k-1
In this question, k=dvc+1

???

13.

a. 2^N  for example, convex set
b. 2^[sqrt(N)]   ???
c.1, it cound be only +1 in this hypothesis
d. double interval
e.

14. ??

15. ??






